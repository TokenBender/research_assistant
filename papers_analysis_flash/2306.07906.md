## WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences

**1. Introduction**

- **Title:** WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences
- **Authors:** Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng Zhang, Yuxiao Dong, and Jie Tang
- **Publication Date:** June 13, 2023 (arXiv preprint)
- **Objective:** To enhance a pre-trained large language model (LLM) with web search and retrieval capabilities while maintaining efficiency for real-world deployments.
- **Number of References:** 41

**2. Section-by-Section Analysis with Citation Extraction**

**2.1 Introduction**

- **Key Points:**
    - LLMs have significantly advanced the boundary of machines' ability in language understanding and generation.
    - Existing studies suggest that recent LLM developments have achieved performance comparable to supervised models in closed-book QA and in-context learning QA.
    - However, LLMs still struggle with challenges requiring rare knowledge.
    - Recent efforts have focused on augmenting LLMs with external knowledge, such as retrieval and web search.
    - WebGPT [24] is a successful example of a web-enhanced QA system that can browse the web, answer complex questions, and provide useful references.
    - However, WebGPT's reliance on expert-level annotations, behavior cloning, and multi-turn web browsing makes it impractical for real-world deployments.
    - WebGLM is a practical web-enhanced QA system based on the 10-billion-parameter GLM (10B) that addresses the limitations of WebGPT.
    - WebGLM outperforms similar-sized WebGPT (13B) and even performs comparably to WebGPT (175B) in human evaluation.

- **Significant Citations:**
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation supports the claim that LLMs have achieved performance comparable to supervised models in closed-book QA and in-context learning QA.
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation introduces WebGPT as a successful example of a web-enhanced QA system and highlights its limitations in terms of practicality.
    - **[6] Du et al., 2022. GLM: General language model pretraining with autoregressive blank infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 320-335.** This citation introduces the GLM-10B model used as the foundation for WebGLM.

**2.2 Related Work**

- **Key Points:**
    - The paper discusses related work in the areas of large language models (LLMs), open-domain question answering, retrieval augmentation, and reinforcement learning from human feedback.
    - LLMs have made significant progress in NLP due to their ability to capture and store versatile knowledge.
    - Open-domain QA datasets like SQUAD [28], Natural Questions [15], Web Questions [2], and MS Marco [25] have contributed to the development of open-domain QA systems.
    - However, most Open QA datasets and models are limited to short answer phrases, while people prefer more informative long-formed answers with references.
    - Retrieval augmentation techniques like BM25, TF-IDF, DPR [14], Contriever [10], REALM [8], RAG [16], Fusion-in-Decoder [11], and Atlas [12] have been explored to improve the performance of QA systems.
    - Reinforcement learning from human feedback (RLHF) has been used to optimize text generation by aligning models with human preferences.

- **Significant Citations:**
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the progress of LLMs in NLP.
    - **[28] Rajpurkar et al., 2016. SQUAD: 100,000+ Questions for Machine Comprehension of Text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 2383-2392.** This citation introduces the SQUAD dataset as a benchmark for traditional QA.
    - **[15] Kwiatkowski et al., 2019. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics 7 (2019), 453-466.** This citation introduces the Natural Questions dataset as a benchmark for open-domain QA.
    - **[14] Karpukhin et al., 2020. Dense Passage Retrieval for Open-Domain Question Answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. 6769-6781.** This citation introduces the DPR model as a representative dense-vector-based retrieval method.
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation highlights WebGPT as a successful example of a web-enhanced QA system and its reliance on RLHF.

**2.3 The WebGLM System**

- **Key Points:**
    - WebGLM is a web-enhanced QA system that combines the advantages of LLMs and well-established open QA studies.
    - WebGLM consists of three main components: an LLM-augmented retriever, a bootstrapped generator, and a human preference-aware scorer.
    - The LLM-augmented retriever uses a two-stage approach: coarse-grained web search and fine-grained LLM-distilled retrieval.
    - The bootstrapped generator is trained on a quoted and long-formed QA dataset (WebGLM-QA) created using LLM in-context learning and filtering strategies.
    - The human preference-aware scorer learns human preferences from online QA forums' thumb-ups instead of relying on expensive expert feedback.

- **Significant Citations:**
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation highlights the limitations of WebGPT in terms of cost and efficiency.
    - **[10] Izacard et al., 2022. Unsupervised Dense Information Retrieval with Contrastive Learning. Transactions on Machine Learning Research (2022).** This citation introduces the Contriever model used as the smaller retriever in WebGLM.
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.
    - **[26] Ouyang et al., 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730-27744.** This citation highlights the importance of aligning models with human preferences.

**2.4 LLM-augmented Retriever**

- **Key Points:**
    - WebGLM's retriever uses a two-stage approach: coarse-grained web search and fine-grained LLM-distilled retrieval.
    - Coarse-grained web search uses third-party search engines (e.g., Google API) to acquire primary candidate web page URLs.
    - Fine-grained LLM-distilled retrieval leverages LLMs' ability to adopt correct references to improve the performance of smaller retrievers like Contriever [10].
    - The paper proposes a method to transfer GPT-3's reference adoption knowledge to Contriever by fine-tuning it on a dataset of manually annotated references.

- **Significant Citations:**
    - **[10] Izacard et al., 2022. Unsupervised Dense Information Retrieval with Contrastive Learning. Transactions on Machine Learning Research (2022).** This citation introduces the Contriever model used as the smaller retriever in WebGLM.
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.

**2.5 Bootstrapped Generator**

- **Key Points:**
    - WebGLM's generator is trained on a quoted and long-formed QA dataset (WebGLM-QA) created using LLM in-context learning and filtering strategies.
    - The paper proposes a method to bootstrap a large amount of quoted long answers using LLMs, questions from ELI5 [7], and a retriever to collect references.
    - The paper also describes strategies for filtering out high-quality samples from the bootstrapped dataset.

- **Significant Citations:**
    - **[7] Fan et al., 2019. ELI5: Long Form Question Answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 3558-3567.** This citation introduces the ELI5 dataset used for bootstrapping the generator.
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.

**2.6 Human Preference-aware Scorer**

- **Key Points:**
    - WebGLM's scorer learns human preferences from online QA forums' thumb-ups instead of relying on expensive expert feedback.
    - The paper describes a method for collecting and preprocessing QA pairs and corresponding user thumb-ups from online QA forums.
    - The paper also describes techniques for mitigating length bias and contrast augmentation in the training data.
    - The scorer is trained using a 6-billion-parameter GLM model and employs supervised fine-tuning (SFT) and comparison training.

- **Significant Citations:**
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation highlights the use of expert feedback in WebGPT.
    - **[26] Ouyang et al., 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730-27744.** This citation highlights the use of RLHF for aligning models with human preferences.
    - **[33] Stiennon et al., 2020. Learning to summarize with human feedback. Advances in Neural Information Processing Systems 33 (2020), 3008-3021.** This citation highlights the use of human feedback for training reward models.

**2.7 Human Evaluation Criteria**

- **Key Points:**
    - The paper introduces human evaluation criteria for both references and answers.
    - Reference evaluation criteria include relevancy, density, truthfulness, toxicity, and social bias.
    - Answer evaluation criteria include fluency, correctness, citation accuracy, truthfulness, objectivity, and redundancy.

- **Significant Citations:**
    - **[4] Celikyilmaz et al., 2020. Evaluation of text generation: A survey. arXiv preprint arXiv:2006.14799 (2020).** This citation highlights the importance of human evaluation for text generation.
    - **[31] Sai et al., 2022. A survey of evaluation metrics used for NLG systems. ACM Computing Surveys (CSUR) 55, 2 (2022), 1-39.** This citation provides a comprehensive overview of evaluation metrics for NLG systems.

**2.8 Experiment**

- **Key Points:**
    - The paper conducts human evaluation experiments using the 272 questions provided on the WebGPT demo website.
    - The paper compares WebGLM's performance with WebGPT-175B, WebGPT-13B, and Perplexity.ai.
    - The paper also conducts a Turing test to compare the quality of answers generated by different systems.
    - The paper performs ablation studies to evaluate the impact of different components and strategies in WebGLM.

- **Significant Citations:**
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation introduces the WebGPT demo website used for evaluation.
    - **[21] Mauldin, 1994. Chatterbots, tinymuds, and the turing test: Entering the loebner prize competition. In AAAI, Vol. 94. 16-21.** This citation introduces the Turing test as a benchmark for evaluating AI systems.

**2.9 Conclusion**

- **Key Points:**
    - WebGLM is a cost-effective and efficient web-enhanced QA system that leverages GPT-3's in-context learning ability to build a bootstrapped dataset.
    - WebGLM's human preference-aware scorer further improves the quality of answers by aligning the model with human preferences.
    - WebGLM outperforms similar-sized WebGPT (13B) and even performs comparably to WebGPT (175B) in human evaluation.

- **Significant Citations:**
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.
    - **[26] Ouyang et al., 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730-27744.** This citation highlights the importance of aligning models with human preferences.

**3. Key Insights and Supporting Literature**

- **Key Insight 1:** LLMs can be effectively used to improve the performance of smaller retrievers by transferring their reference adoption knowledge.
    - **[10] Izacard et al., 2022. Unsupervised Dense Information Retrieval with Contrastive Learning. Transactions on Machine Learning Research (2022).** This citation introduces the Contriever model used as the smaller retriever in WebGLM.
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.

- **Key Insight 2:** Bootstrapping a large dataset of quoted and long-formed QA using LLMs and filtering strategies can be a cost-effective alternative to relying on expensive expert annotations.
    - **[7] Fan et al., 2019. ELI5: Long Form Question Answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 3558-3567.** This citation introduces the ELI5 dataset used for bootstrapping the generator.
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.

- **Key Insight 3:** Learning human preferences from online QA forums' thumb-ups can be a cost-effective alternative to relying on expensive expert feedback for training reward models.
    - **[26] Ouyang et al., 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730-27744.** This citation highlights the importance of aligning models with human preferences.
    - **[33] Stiennon et al., 2020. Learning to summarize with human feedback. Advances in Neural Information Processing Systems 33 (2020), 3008-3021.** This citation highlights the use of human feedback for training reward models.

**4. Experimental Methodology and Its Foundations**

- **Experimental Setup:**
    - Human evaluation experiments were conducted using the 272 questions provided on the WebGPT demo website.
    - The paper compares WebGLM's performance with WebGPT-175B, WebGPT-13B, and Perplexity.ai.
    - The paper also conducts a Turing test to compare the quality of answers generated by different systems.
    - Ablation studies were performed to evaluate the impact of different components and strategies in WebGLM.

- **Cited Works for Methodology:**
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation introduces the WebGPT demo website used for evaluation.
    - **[21] Mauldin, 1994. Chatterbots, tinymuds, and the turing test: Entering the loebner prize competition. In AAAI, Vol. 94. 16-21.** This citation introduces the Turing test as a benchmark for evaluating AI systems.

- **Novel Aspects of Methodology:**
    - The paper proposes a novel method for transferring GPT-3's reference adoption knowledge to Contriever by fine-tuning it on a dataset of manually annotated references.
    - The paper also proposes a novel method for bootstrapping a large dataset of quoted and long-formed QA using LLMs and filtering strategies.

**5. Results in Context**

- **Main Results:**
    - WebGLM (10B) outperforms similar-sized WebGPT (13B) and even performs comparably to WebGPT (175B) in human evaluation.
    - WebGLM achieves higher performance in fluency, truthfulness, and redundancy compared to WebGPT-13B, Perplexity.ai, and WebGPT-175B.
    - WebGLM performs comparably to WebGPT-175B in the correctness metric.
    - WebGLM outperforms Perplexity.ai on the Natural Questions and Web Questions benchmarks.
    - WebGLM achieves comparable performance to WebGPT-175B on the TriviaQA benchmark.

- **Citations for Comparison with Existing Literature:**
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation introduces WebGPT as a benchmark for comparison.
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.

- **Confirmation, Contradiction, or Extension of Cited Works:**
    - WebGLM's results confirm the potential of LLMs for in-context learning, as demonstrated by WebGPT [24].
    - WebGLM's results extend the work of WebGPT by demonstrating that a smaller model can achieve comparable performance with a more efficient and cost-effective approach.

**6. Discussion and Related Work**

- **Situating the Work within Existing Literature:**
    - The authors situate their work within the broader context of web-enhanced QA systems, highlighting the challenges and limitations of existing approaches.
    - They emphasize the importance of efficiency and cost-effectiveness for real-world deployments.
    - They also discuss the importance of aligning models with human preferences.

- **Key Papers Cited in Discussion/Related Work:**
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation highlights WebGPT as a benchmark for comparison and discusses its limitations.
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.
    - **[26] Ouyang et al., 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730-27744.** This citation highlights the importance of aligning models with human preferences.

- **Highlighting Novelty/Importance of the Work:**
    - The authors highlight the novelty of WebGLM's approach, which addresses the limitations of WebGPT in terms of cost and efficiency.
    - They emphasize the importance of WebGLM's human preference-aware scorer for improving the quality of answers.

**7. Future Work and Open Questions**

- **Areas for Further Research:**
    - The authors suggest exploring the use of other LLMs for bootstrapping the generator and fine-tuning the retriever.
    - They also suggest investigating the use of different reward models for the human preference-aware scorer.

- **Citations for Future Work:**
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.
    - **[26] Ouyang et al., 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730-27744.** This citation highlights the importance of aligning models with human preferences.

**8. Critical Analysis of Citation Usage**

- **Effectiveness of Citation Usage:**
    - The authors effectively use citations to support their arguments and findings.
    - They provide relevant citations to introduce key concepts, discuss related work, and justify their methodological choices.

- **Areas for Additional Citations:**
    - The paper could benefit from additional citations in the discussion of retrieval augmentation techniques, particularly those related to dense-vector-based methods.
    - The paper could also benefit from additional citations in the discussion of reinforcement learning from human feedback, particularly those related to the use of reward models.

- **Potential Biases in Citation Selection:**
    - The paper relies heavily on citations from OpenAI and Google Magenta, which may reflect a bias towards these organizations.
    - The paper could benefit from a more diverse selection of citations to represent the broader research landscape in web-enhanced QA.

**9. Final Summary**

- **Contribution to the Field:**
    - WebGLM is a significant contribution to the field of web-enhanced QA systems.
    - It addresses the limitations of existing approaches in terms of cost and efficiency.
    - It demonstrates the potential of LLMs for improving the performance of smaller retrievers and bootstrapping large datasets.

- **Influential/Frequently Cited Works:**
    - **[24] Nakano et al., 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).** This citation introduces WebGPT as a benchmark for comparison and discusses its limitations.
    - **[3] Brown et al., 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.** This citation highlights the potential of LLMs for in-context learning.

- **Assessment of Literature Integration:**
    - The paper effectively integrates existing literature to support its claims and findings.
    - It provides a comprehensive overview of related work and highlights the novelty of its approach.
    - The paper's use of citations helps readers understand the factual basis of the research and its relationship to existing literature.