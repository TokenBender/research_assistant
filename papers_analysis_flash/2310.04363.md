## Amortizing Intractable Inference in Large Language Models: A Citation-Focused Analysis

This paper, published in ICLR 2024 by Edward J. Hu, Moksh Jain, Eric Elmoznino, Guillaume Lajoie, Yoshua Bengio, Nikolay Malkin, and Younesse Kaddar, explores the use of generative flow networks (GFlowNets) to fine-tune large language models (LLMs) for sampling from intractable posterior distributions. The paper cites a total of 77 references.

### 1. Introduction

The paper aims to address the limitation of autoregressive LLMs, which are only tractable for start-to-end autoregressive sampling. Many tasks of interest, such as sequence continuation, infilling, and constrained generation, involve sampling from intractable posterior distributions. The authors propose using amortized Bayesian inference to sample from these intractable posteriors, achieved by fine-tuning LLMs via GFlowNets.

### 2. Section-by-Section Analysis with Citation Extraction

**2.1 Introduction**

- **Claim:** Autoregressive LLMs are vast stores of world knowledge.
    - **Citation:** (Petroni et al., 2019)
    - **Relevance:** This citation establishes the foundation of LLMs as knowledge repositories, setting the stage for the paper's focus on leveraging this knowledge for more complex tasks.
- **Claim:** Tractable inference over this knowledge is limited to sampling conditioned on a prefix.
    - **Citation:** (Petroni et al., 2019)
    - **Relevance:** This citation highlights the limitation of traditional LLM inference, motivating the need for the proposed GFlowNet approach.
- **Claim:** Many useful tasks involve intractable inference in LLMs.
    - **Citations:** (Zhu et al., 2019; Liu et al., 2019; Hokamp & Liu, 2017; Hu et al., 2019)
    - **Relevance:** These citations provide specific examples of tasks that require intractable inference, demonstrating the practical significance of the paper's research.
- **Claim:** Reasoning can be framed as probabilistic inference.
    - **Citation:** (Gershman & Goodman, 2014)
    - **Relevance:** This citation connects the paper's work to the broader field of probabilistic reasoning, providing a theoretical framework for understanding the challenges of intractable inference in LLMs.
- **Claim:** Chain-of-thought reasoning can be interpreted as a problem of intractable posterior inference.
    - **Citations:** (Wei et al., 2022; Kojima et al., 2022)
    - **Relevance:** This citation introduces the specific problem of chain-of-thought reasoning, which the paper uses as a key application for its GFlowNet approach.

**2.2 Motivating Example: Generating Random Numbers with LLMs**

- **Claim:** Pretrained LLMs perform poorly on generating random numbers from a given distribution.
    - **Citation:** (Renda et al., 2023)
    - **Relevance:** This citation highlights the limitations of traditional fine-tuning methods for LLMs, setting the stage for the introduction of GFlowNets.
- **Claim:** Reward-maximizing RL methods can teach the model to generate valid numbers but fail to resolve distribution skew.
    - **Citations:** (Wang & Komatsuzaki, 2021; Benford, 1938)
    - **Relevance:** These citations provide context for the limitations of reward-maximizing RL, emphasizing the need for a more principled approach like GFlowNets.
- **Claim:** GFlowNet objectives provide a principled and flexible approach to fine-tuning LLMs to match a target distribution.
    - **Citations:** (Bengio et al., 2021; Madan et al., 2023)
    - **Relevance:** This citation introduces GFlowNets as a solution to the limitations of traditional fine-tuning methods, highlighting their ability to match target distributions.

**2.3 Fine-Tuning LLMs to Sample from Intractable Distributions**

- **Claim:** Intractable inference emerges from interesting applications of LLMs, such as chain-of-thought reasoning.
    - **Citations:** (Wei et al., 2022; Kojima et al., 2022)
    - **Relevance:** This section further emphasizes the importance of addressing intractable inference in LLMs, specifically focusing on the problem of chain-of-thought reasoning.
- **Claim:** Autoregressive language models decompose the distribution over sequences of tokens as a product of ordered conditionals.
    - **Citation:** (Bengio et al., 2021)
    - **Relevance:** This citation provides a theoretical foundation for understanding the challenges of sampling from intractable posterior distributions in LLMs.
- **Claim:** Sampling from other conditional distributions is intractable.
    - **Citation:** (Bengio et al., 2021)
    - **Relevance:** This citation reinforces the need for the proposed GFlowNet approach to address the intractability of sampling from these distributions.

**2.4 Tempered and Contrastive Sampling**

- **Claim:** Tempered sampling is used to sample from a low-temperature distribution over sequences.
    - **Citations:** (Tillmann & Ney, 2003; Malkin et al., 2022b; Li et al., 2023)
    - **Relevance:** This citation introduces the concept of tempered sampling, providing context for the paper's focus on sampling from intractable distributions.

**2.5 Infilling and Reverse Generation**

- **Claim:** Infilling is the task of sampling a sequence of tokens conditioned on both its prior and subsequent context.
    - **Citations:** (Liu et al., 2019; Zhu et al., 2019; Donahue et al., 2020; Susanto et al., 2020; Lu et al., 2022a)
    - **Relevance:** This citation provides specific examples of tasks that require intractable inference, further motivating the need for the proposed GFlowNet approach.

**2.6 Constrained Generation**

- **Claim:** Constrained generation involves sampling from a distribution with constraints and penalties.
    - **Citations:** (Liu et al., 2021; Schmaltz et al., 2016; Hokamp & Liu, 2017; Hu et al., 2019; Sha, 2020; Lu et al., 2022b; Yang & Klein, 2021; Meng et al., 2022)
    - **Relevance:** This citation provides a comprehensive overview of existing approaches to constrained generation, highlighting the challenges and limitations of these methods.

**2.7 Reasoning Through Latent Variables**

- **Claim:** Chain-of-thought reasoning can be seen as posterior inference in latent variable models.
    - **Citations:** (Wei et al., 2022; Kojima et al., 2022; Schick & Sch√ºtze, 2021)
    - **Relevance:** This citation connects the paper's work to the broader field of latent variable modeling, providing a theoretical framework for understanding the challenges of intractable inference in LLMs.

**2.8 Amortized Inference with GFlowNet Objectives**

- **Claim:** GFlowNets learn policies to sample sequences from a distribution given an unnormalized density (reward).
    - **Citations:** (Bengio et al., 2021; 2023; Malkin et al., 2022a)
    - **Relevance:** This citation introduces GFlowNets as a powerful tool for sampling from intractable distributions, providing a foundation for the paper's proposed approach.
- **Claim:** The goal of GFlowNet training is to fit a parametric policy such that the likelihood of generating a complete sequence is proportional to its reward.
    - **Citations:** (Madan et al., 2023; Deleu et al., 2022)
    - **Relevance:** This citation clarifies the objective of GFlowNet training, highlighting its ability to match target distributions.

**2.9 Empirical Results**

- **Claim:** GFlowNet fine-tuning improves sample diversity and data efficiency for text generation tasks.
    - **Citations:** (Vijayakumar et al., 2018; Shao et al., 2017; Fan et al., 2018; Holtzman et al., 2019; Shih et al., 2023)
    - **Relevance:** This section presents empirical evidence for the effectiveness of GFlowNet fine-tuning, comparing it to existing methods for text generation.
- **Claim:** GFlowNet fine-tuning outperforms baselines on infilling tasks, generating infills that link the beginning and the end of the story coherently.
    - **Citations:** (Zhu et al., 2019; Mostafazadeh et al., 2016; Zhang et al., 2020b; He et al., 2021; Papineni et al., 2002; Wu et al., 2016)
    - **Relevance:** This section demonstrates the effectiveness of GFlowNet fine-tuning for a specific task, infilling, highlighting its ability to generate coherent and meaningful text.
- **Claim:** GFlowNet fine-tuning outperforms supervised fine-tuning and PPO on subjectivity classification and integer arithmetic tasks.
    - **Citations:** (Pang & Lee, 2004; Radford et al., 2019; Dohan et al., 2022; Sordoni et al., 2023; Cobbe et al., 2021; Schick et al., 2021; Zhou et al., 2022; Gao et al., 2023; Eysenbach & Levine, 2022)
    - **Relevance:** This section provides further empirical evidence for the effectiveness of GFlowNet fine-tuning, demonstrating its superiority over other methods for a variety of tasks.

**2.10 Further Related Work**

- **Claim:** Sampling from intractable posterior distributions has been an object of study for tasks such as infilling and constrained generation.
    - **Citations:** (Miao et al., 2019; Zhang et al., 2020a; Malkin et al., 2021; Lew et al., 2023; Wang & Cho, 2019; Goyal et al., 2022; Yamakoshi et al., 2022; Torroba Hennigen & Kim, 2023)
    - **Relevance:** This section provides a comprehensive overview of existing approaches to sampling from intractable distributions, highlighting the challenges and limitations of these methods.
- **Claim:** GFlowNets were originally proposed to learn policies for sampling discrete compositional objects from an unnormalized reward distribution.
    - **Citations:** (Bengio et al., 2021; Jain et al., 2023; 2022; Malkin et al., 2023; Zimmermann et al., 2023; Deleu et al., 2022; 2023; van Krieken et al., 2023; Hu et al., 2023)
    - **Relevance:** This section provides a comprehensive overview of the development and applications of GFlowNets, highlighting their versatility and potential for addressing intractable inference problems.
- **Claim:** Chain-of-thought reasoning in LLMs involves generating a latent reasoning chain.
    - **Citations:** (Wei et al., 2022; Kojima et al., 2022; Wang et al., 2023b; Xu et al., 2023; Zhou et al., 2022; Zelikman et al., 2022; Phan et al., 2023)
    - **Relevance:** This section provides a comprehensive overview of existing approaches to chain-of-thought reasoning, highlighting the challenges and limitations of these methods.

**2.11 Conclusion**

- **Claim:** GFlowNet fine-tuning provides a principled approach to sampling from intractable posterior distributions in LLMs.
    - **Citations:** (Bengio et al., 2021; 2023; Malkin et al., 2022a; Madan et al., 2023; Deleu et al., 2022)
    - **Relevance:** This section summarizes the paper's key contribution, highlighting the effectiveness of GFlowNet fine-tuning for addressing intractable inference problems in LLMs.

### 3. Key Insights and Supporting Literature

- **Key Insight:** GFlowNet fine-tuning offers a better fidelity-diversity trade-off for text generation tasks compared to traditional methods.
    - **Citations:** (Vijayakumar et al., 2018; Shao et al., 2017; Fan et al., 2018; Holtzman et al., 2019; Shih et al., 2023)
    - **Contribution:** This insight demonstrates the practical benefits of GFlowNet fine-tuning, highlighting its ability to generate diverse and high-quality text.
- **Key Insight:** GFlowNet fine-tuning improves sample efficiency and generalization on downstream tasks compared to maximum-likelihood training or reward-maximizing policy optimization.
    - **Citations:** (Bengio et al., 2021; 2023; Malkin et al., 2022a; Madan et al., 2023; Deleu et al., 2022; Pang & Lee, 2004; Radford et al., 2019; Dohan et al., 2022; Sordoni et al., 2023; Cobbe et al., 2021; Schick et al., 2021; Zhou et al., 2022; Gao et al., 2023; Eysenbach & Levine, 2022)
    - **Contribution:** This insight highlights the practical advantages of GFlowNet fine-tuning, demonstrating its ability to improve both the efficiency and generalizability of LLM inference.

### 4. Experimental Methodology and Its Foundations

The paper uses GFlowNets to fine-tune LLMs for sampling from intractable posterior distributions. The authors use a modified version of the subtrajectory balance (SubTB) objective (Madan et al., 2023) to account for trajectories being terminable at all states (Deleu et al., 2022). The GFlowNet policy is parameterized as an autoregressive language model that samples the latent sequence Z one token at a time from left to right. The reward is set to PLM(XZY) ‚àù PLM(Z | X, Y), enabling the model to learn a sampler for the posterior at convergence.

### 5. Results in Context

- **Result:** GFlowNet fine-tuning outperforms baselines on sentence continuation tasks, generating samples with higher log-likelihood and diversity.
    - **Citations:** (Vijayakumar et al., 2018; Shao et al., 2017; Fan et al., 2018; Holtzman et al., 2019; Shih et al., 2023)
    - **Context:** This result confirms the paper's claim that GFlowNet fine-tuning improves sample diversity and data efficiency for text generation tasks.
- **Result:** GFlowNet fine-tuning outperforms baselines on story infilling tasks, generating infills that link the beginning and the end of the story coherently.
    - **Citations:** (Zhu et al., 2019; Mostafazadeh et al., 2016; Zhang et al., 2020b; He et al., 2021; Papineni et al., 2002; Wu et al., 2016)
    - **Context:** This result further supports the paper's claim that GFlowNet fine-tuning is effective for tasks involving intractable inference.
- **Result:** GFlowNet fine-tuning outperforms supervised fine-tuning and PPO on subjectivity classification and integer arithmetic tasks.
    - **Citations:** (Pang & Lee, 2004; Radford et al., 2019; Dohan et al., 2022; Sordoni et al., 2023; Cobbe et al., 2021; Schick et al., 2021; Zhou et al., 2022; Gao et al., 2023; Eysenbach & Levine, 2022)
    - **Context:** This result provides further evidence for the paper's claim that GFlowNet fine-tuning is a superior method for addressing intractable inference problems in LLMs.

### 6. Discussion and Related Work

The authors situate their work within the existing literature on sampling from intractable distributions, highlighting the limitations of traditional methods such as MCMC and reward-maximizing RL. They emphasize the advantages of GFlowNets, including improved sample diversity, data efficiency, and out-of-distribution generalization. The authors also discuss the relationship between their work and chain-of-thought reasoning, suggesting that GFlowNet fine-tuning can be used to learn models that can generate more accurate and diverse reasoning chains.

### 7. Future Work and Open Questions

The authors suggest several areas for future research, including:

- Investigating transfer and generalization across tasks, potentially building a "universal reasoner" that can be used for a variety of tasks.
- Exploring the use of more capable base LLMs as starting points for GFlowNet fine-tuning.
- Quantifying epistemic uncertainty using GFlowNet sampling.
- Extending the GFlowNet paradigm to latent variables with richer generative processes than left-to-right sampling.

### 8. Critical Analysis of Citation Usage

The authors effectively use citations to support their arguments and findings. They provide a comprehensive overview of existing literature on sampling from intractable distributions, highlighting the limitations of traditional methods and the advantages of GFlowNets. They also use citations to connect their work to the broader fields of probabilistic reasoning and chain-of-thought reasoning, providing a theoretical framework for understanding their research.

However, there are a few areas where additional citations might have been beneficial. For example, the authors could have provided more citations to support their claims about the limitations of reward-maximizing RL methods. They could also have provided more citations to support their claims about the potential benefits of GFlowNet fine-tuning for tasks such as program synthesis and planning.

Overall, the authors demonstrate a strong understanding of the relevant literature and effectively use citations to support their arguments and findings.

### 9. Final Summary

This paper makes a significant contribution to the field of deep learning by proposing a novel approach to fine-tuning LLMs for sampling from intractable posterior distributions. The authors demonstrate the effectiveness of GFlowNet fine-tuning for a variety of tasks, including text generation, infilling, subjectivity classification, and integer arithmetic. The paper provides a comprehensive overview of existing literature on sampling from intractable distributions, highlighting the limitations of traditional methods and the advantages of GFlowNets. The authors also discuss the relationship between their work and chain-of-thought reasoning, suggesting that GFlowNet fine-tuning can be used to learn models that can generate more accurate and diverse reasoning chains. The paper concludes by suggesting several areas for future research, including investigating transfer and generalization across tasks, exploring the use of more capable base LLMs, and extending the GFlowNet paradigm to latent variables with richer generative processes.

The most influential or frequently cited works used throughout the paper include:

- (Bengio et al., 2021)
- (Madan et al., 2023)
- (Deleu et al., 2022)
- (Wei et al., 2022)
- (Kojima et al., 2022)

The paper effectively integrates existing literature to support its claims and findings, providing a strong foundation for future research in this area.