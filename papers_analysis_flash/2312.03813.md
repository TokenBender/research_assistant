Okay, here's a comprehensive analysis of the provided paper in Markdown format, following the structure you outlined:


# Improving Activation Steering in Language Models with Mean-Centring: A Citation Analysis

## 1. Introduction

**Title:** Improving Activation Steering in Language Models with Mean-Centring
**Authors:** Ole Jorgensen, Dylan Cope, Nandi Schoots, Murray Shanahan
**Publication Date:** December 6, 2023 (arXiv preprint)
**Objective:** The research aims to improve the effectiveness of activation steering in large language models by introducing a simple technique called mean-centring, which leverages dataset-specific activation averages to generate more effective steering vectors.
**Total Number of References:** 55


## 2. Section-by-Section Analysis with Citation Extraction

### 2.1 Introduction

**Summary:** This section introduces the increasing capabilities of LLMs and the challenges associated with mitigating issues like social biases. It highlights the limitations of existing approaches like weight modification and introduces activation steering as a promising alternative.

**Significant Citations:**

* **Claim:** "Large Language Models (LLMs) have become increasingly capable over the past few years across a diverse range of tasks (Peters et al. 2018; Radford et al. 2019; OpenAI 2023)."
    * **Citation:** Peters, M. E.; Neumann, M.; Iyyer, M.; Gardner, M.; Clark, C.; Lee, K.; and Zettlemoyer, L. 2018. Deep contextualized word representations. arXiv:1802.05365.
    * **Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; and Sutskever, I. 2019. Language Models are Unsupervised Multitask Learners. Technical report, OpenAI.**
    * **OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774.**
    * **Relevance:** These citations establish the context of LLMs' growing capabilities, providing examples of influential models and their advancements.
* **Claim:** "However, in part due to a lack of understanding of how these capabilities are implemented, we are unable to address issues such as social biases (Abid, Farooqi, and Zou 2021)."
    * **Citation:** Abid, A.; Farooqi, M.; and Zou, J. 2021. Persistent Anti-Muslim Bias in Large Language Models. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, AIES '21, 298-306. New York, NY, USA: Association for Computing Machinery. ISBN 9781450384735.
    * **Relevance:** This citation highlights the problem of social biases in LLMs, motivating the need for better control mechanisms like activation steering.
* **Claim:** "A recent approach to controlling LLMs is activation steering (Turner et al. 2023; Li et al. 2023; Subramani, Suresh, and Peters 2022), or similarly representation engineering (Zou et al. 2023)."
    * **Citation:** Turner, A. M.; Thiergart, L.; Udell, D.; Leech, G.; Mini, U.; and MacDiarmid, M. 2023. Activation Addition: Steering Language Models Without Optimization. arXiv:2308.10248.
    * **Li, K.; Patel, O.; Viégas, F.; Pfister, H.; and Wattenberg, M. 2023. Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. In Advances in Neural Information Processing Systems.**
    * **Subramani, N.; Suresh, N.; and Peters, M. 2022. Extracting Latent Steering Vectors from Pretrained Language Models. In Findings of the Association for Computational Linguistics: ACL 2022.**
    * **Zou, A.; Phan, L.; Chen, S.; Campbell, J.; Guo, P.; Ren, R.; Pan, A.; Yin, X.; Mazeika, M.; Dombrowski, A.-K.; Goel, S.; Li, N.; Byun, M. J.; Wang, Z.; Mallen, A.; Basart, S.; Koyejo, S.; Song, D.; Fredrikson, M.; Kolter, J. Z.; and Hendrycks, D. 2023. Representation Engineering: A Top-Down Approach to AI Transparency. arXiv:2310.01405.**
    * **Relevance:** These citations introduce the concept of activation steering and related techniques, establishing the paper's position within the current research landscape.


### 2.2 Related Work

**Summary:** This section reviews existing literature on the linear representation hypothesis and activation steering, highlighting the foundation for the proposed mean-centring method.

**Significant Citations:**

* **Claim:** "The linear representation hypothesis (Elhage et al. 2022) proposes that many human-interpretable high-level concepts are represented linearly as directions in the residual stream of language models."
    * **Citation:** Elhage, N.; Hume, T.; Olsson, C.; Schiefer, N.; Henighan, T.; Kravec, S.; Hatfield-Dodds, Z.; Lasenby, R.; Drain, D.; Chen, C.; Grosse, R.; McCandlish, S.; Kaplan, J.; Amodei, D.; Wattenberg, M.; and Olah, C. 2022. Toy Models of Superposition. Transformer Circuits Thread.
    * **Relevance:** This citation introduces the linear representation hypothesis, which is a key concept underlying the paper's approach to steering.
* **Claim:** "There is significant evidence for the linear structure of neural network representations, including linear operations on Word2Vec embeddings capturing semantic meaning (Mikolov, Yih, and Zweig 2013)."
    * **Citation:** Mikolov, T.; Yih, W.-t.; and Zweig, G. 2013. Linguistic Regularities in Continuous Space Word Representations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 746-751.
    * **Relevance:** This citation provides evidence for the linear representation hypothesis, supporting the idea that concepts can be represented as directions in the activation space.
* **Claim:** "Multiple works have demonstrated the anisotropy of the activations of language models (Ethayarajh 2019; Cai et al. 2021)."
    * **Citation:** Ethayarajh, K. 2019. How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 55–65. Hong Kong, China: Association for Computational Linguistics.
    * **Cai, X.; Huang, J.; Bian, Y.; and Church, K. 2021. Isotropy in the Contextual Embedding Space: Clusters and Manifolds. In International Conference on Learning Representations.**
    * **Relevance:** This citation introduces the concept of anisotropy in language model activations, which is a key factor motivating the mean-centring approach.
* **Claim:** "There have been recent efforts to control the outputs of language models through activation steering, i.e. adding vectors into the activations of a model at inference time."
    * **Citation:** Turner et al. (2023), Li et al. (2023), Subramani et al. (2022), Zou et al. (2023) (as mentioned in the introduction).
    * **Relevance:** This reinforces the importance of activation steering as a method for controlling LLMs, setting the stage for the paper's contribution.


### 3. Mean-Centred Activation Steering

**Summary:** This section introduces the core concept of mean-centring. It explains how a distillation vector can be extracted from a target dataset by subtracting the mean of all training activations from the mean of the target dataset's activations.

**Significant Citations:**

* **Claim:** "Previous work (Cai et al. 2021) has demonstrated that the activations of GPT-2 Small and BERT activations typically have a non-zero mean (Section 2.3), across all layers."
    * **Citation:** Cai, X.; Huang, J.; Bian, Y.; and Church, K. 2021. Isotropy in the Contextual Embedding Space: Clusters and Manifolds. In International Conference on Learning Representations.
    * **Relevance:** This citation provides evidence for the existence of a non-zero mean in language model activations, which is a crucial observation for the mean-centring method.
* **Claim:** "Mu and Viswanath (2018) improve downstream performance on these word representations by subtracting the mean, and then projecting on the dominant remaining directions. This directly inspires our own method of mean-centring."
    * **Citation:** Mu, J.; and Viswanath, P. 2018. All-but-the-Top: Simple and Effective Postprocessing for Word Representations. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings.
    * **Relevance:** This citation highlights the inspiration for the mean-centring method, showing that similar techniques have been successfully applied to word embeddings.


### 4. Experimental Evaluations

**Summary:** This section presents the experimental results of the mean-centring method across three different tasks: toxicity removal, genre steering in story generation, and improving function vector extraction.

**Significant Citations:**

* **Claim:** "We firstly evaluate its effectiveness at removing toxicity from language models (Section 4.1), demonstrating that it is comparable to an existing steering method, namely counterbalanced subtractions from Turner et al. (2023)."
    * **Citation:** Turner et al. (2023) (as mentioned in the introduction).
    * **Relevance:** This citation establishes the baseline for comparison, highlighting the existing method (counterbalanced subtractions) against which the mean-centring method is evaluated.
* **Claim:** "We perform experiments on GPT-2 Small, Medium, Large and XL (Radford et al. 2019), GPT-J-6B (Wang and Komatsuzaki 2021), GPT-NeoX-20B (Black et al. 2022), Llama-2 7B and Llama-2 13B (Touvron et al. 2023)."
    * **Citation:** Radford et al. (2019) (as mentioned in the introduction).
    * **Wang, B.; and Komatsuzaki, A. 2021. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax.**
    * **Black, S.; Biderman, S.; Hallahan, E.; Anthony, Q.; Gao, L.; Golding, L.; He, H.; Leahy, C.; McDonell, K.; Phang, J.; Pieler, M.; Prashanth, U. S.; Purohit, S.; Reynolds, L.; Tow, J.; Wang, B.; and Weinbach, S. 2022. GPT-NeoX-20B: An Open-Source Autoregressive Language Model. In Fan, A.; Ilic, S.; Wolf, T.; and Gallé, M., eds., Proceedings of BigScience Episode #5 – Workshop on Challenges & Perspectives in Creating Large Language Models, 95–136. virtual+Dublin: Association for Computational Linguistics.**
    * **Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi, A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; Bikel, D.; Blecher, L.; Ferrer, C. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes, J.; Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini, S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; Kloumann, I.; Korenev, A.; Koura, P. S.; Lachaux, M.-A.; Lavril, T.; Lee, J.; Liskovich, D.; Lu, Y.; Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poulton, A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, A.; Silva, R.; Smith, E. M.; Subramanian, R.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.; Kuan, J. X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, S.; Rodriguez, A.; Stojnic, R.; Edunov, S.; and Scialom, T. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288.**
    * **Relevance:** These citations list the specific language models used in the experiments, providing context for the reproducibility and generalizability of the findings.


### 4.1 Removing Toxicity Experiments

**Summary:** This subsection focuses on the effectiveness of mean-centring in reducing the toxicity of generated text. It compares the method to ActAdd (Turner et al., 2023) and demonstrates its ability to reduce toxicity without significantly increasing positive sentiment.

**Significant Citations:**

* **Claim:** "We prompt GPT-2 Small to generate continuations of toxic comments, where prompts are created using a derivative of the Jigsaw Toxic Comments dataset (Adams et al. 2017; Borkan et al. 2019) that only included toxic comments (Appendix C.3)."
    * **Citation:** Adams, C.; Sorensen, J.; Elliott, J.; Dixon, L.; McDonald, M.; nithum; and Cukierski, W. 2017. Toxic Comment Classification Challenge.
    * **Borkan, D.; Dixon, L.; Sorensen, J.; Thain, N.; and Vasserman, L. 2019. Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification. In Companion Proceedings of The 2019 World Wide Web Conference, 491-500. Association for Computing Machinery.**
    * **Relevance:** These citations introduce the dataset used for the toxicity removal experiments, providing context for the evaluation methodology.
* **Claim:** "We also find that the mean-centring (Non-Toxic) method is able to reduce the toxicity of the model without substantially increasing the sentiment of responses."
    * **Citation:**  No specific citation is directly linked to this claim, but it builds upon the results presented in Figure 2 and the discussion of the different steering methods.
    * **Relevance:** This claim highlights a key finding of the toxicity removal experiments, demonstrating the ability of mean-centring to achieve a specific desired outcome.


### 4.2 Steering Story Continuations

**Summary:** This subsection explores the application of mean-centring to steer the genre of generated stories. It demonstrates that the method can effectively influence the frequency of genre-specific words in the generated text.

**Significant Citations:**

* **Claim:** "GPT-2 Small was prompted with the beginning of a story in a fantasy, sci-fi, or sports genre, before mean-centred steering is used to produce continuations of the story in another genre."
    * **Citation:** Radford et al. (2019) (as mentioned in the introduction).
    * **Relevance:** This citation provides context for the experimental setup, specifying the language model and the type of prompt used.
* **Claim:** "We provide evidence that the mean-centred distillation vectors are more interpretable than the non mean-centred distillation vectors in Table 1 and Appendix B using the Logit Lens, as introduced by (nostalgebrist 2020)."
    * **Citation:** nostalgebrist. 2020. Interpreting GPT: The Logit Lens.
    * **Relevance:** This citation introduces the Logit Lens technique, which is used to analyze the interpretability of the generated steering vectors.


### 4.3 Better Function Vectors

**Summary:** This subsection investigates the use of mean-centring to improve the extraction of function vectors, which are used to trigger specific input-output functions in LLMs. It shows that mean-centring can lead to significant improvements in accuracy for certain tasks.

**Significant Citations:**

* **Claim:** "As a final application of mean-centring in a domain where counterbalanced subtractions cannot be applied, we consider recent work on extracting function vectors by Todd et al. (2023)."
    * **Citation:** Todd, E.; Li, M. L.; Sharma, A. S.; Mueller, A.; Wallace, B. C.; and Bau, D. 2023. Function Vectors in Large Language Models. arXiv: 2310.15213.
    * **Relevance:** This citation introduces the concept of function vectors and the work of Todd et al., which serves as a basis for the experimental setup in this section.
* **Claim:** "Using mean-centring at layer 15 gives an accuracy of 45.7% across the 6 tasks studied, which is significantly better than the accuracy without mean-centring of 29.2%."
    * **Citation:** No specific citation is directly linked to this claim, but it builds upon the results presented in Figure 4 and the discussion of the different steering methods.
    * **Relevance:** This claim highlights a key finding of the function vector experiments, demonstrating the effectiveness of mean-centring in improving accuracy.


### 5. Conclusion

**Summary:** This section summarizes the main findings of the paper, highlighting the benefits of mean-centring for activation steering and suggesting directions for future research.

**Significant Citations:**

* **Claim:** "We hypothesize that other methods such as LAT scans (Zou et al. 2023) and counterbalanced subtractions (Turner et al. 2023) may implicitly perform mean-centring."
    * **Citation:** Zou et al. (2023) and Turner et al. (2023) (as mentioned in the introduction).
    * **Relevance:** This claim suggests a potential connection between mean-centring and other existing methods, opening up avenues for future research.
* **Claim:** "This could allow for other researchers to easily use activation steering in their own work, with only a dataset exhibiting the desired behaviour."
    * **Citation:** No specific citation is directly linked to this claim, but it builds upon the overall findings of the paper and the simplicity of the mean-centring method.
    * **Relevance:** This claim highlights the potential impact of the proposed method, suggesting that it could make activation steering more accessible to a wider research community.


## 3. Key Insights and Supporting Literature

* **Insight:** Language model activations are typically not centered around the origin, but exhibit anisotropy.
    * **Supporting Citations:** Ethayarajh (2019), Cai et al. (2021).
    * **Explanation:** These citations establish the presence of anisotropy, a key observation that motivates the mean-centring approach.
* **Insight:** Mean-centring can effectively improve activation steering by removing the bias inherent in language model activations.
    * **Supporting Citations:** Mu and Viswanath (2018), Cai et al. (2021).
    * **Explanation:** These citations provide the foundation for understanding the bias removal aspect of mean-centring, drawing parallels to similar techniques in word embeddings.
* **Insight:** Mean-centring can be applied to a wider range of tasks compared to existing methods like counterbalanced subtractions.
    * **Supporting Citations:** Turner et al. (2023).
    * **Explanation:** This insight highlights the versatility of mean-centring, contrasting it with the limitations of other methods that require specific counterbalancing concepts.
* **Insight:** Mean-centring can improve the accuracy of function vector extraction in LLMs.
    * **Supporting Citations:** Todd et al. (2023).
    * **Explanation:** This insight demonstrates the effectiveness of mean-centring in a specific application area, building upon the work of Todd et al. on function vectors.


## 4. Experimental Methodology and Its Foundations

**Experimental Setup:** The paper evaluates the mean-centring method across three main tasks: toxicity removal, genre steering in story generation, and function vector extraction. It uses a variety of language models, including GPT-2 variants, GPT-J, GPT-NeoX, and Llama-2. The experiments involve prompting the models with different inputs and analyzing the outputs using metrics like toxicity scores, sentiment scores, and word frequency analysis.

**Foundations in Cited Works:**

* **Activation Steering:** The authors build upon the existing work on activation steering (Turner et al., 2023; Li et al., 2023; Subramani et al., 2022; Zou et al., 2023), using it as a framework for their experiments.
* **Function Vector Extraction:** The function vector extraction experiments are based on the work of Todd et al. (2023).
* **Anisotropy and Bias:** The concept of anisotropy and bias in language model activations, as discussed by Ethayarajh (2019) and Cai et al. (2021), forms the basis for the mean-centring method.

**Novel Aspects of Methodology:**

The primary novel aspect is the introduction of the mean-centring technique itself. The authors justify this novel approach by referencing the work of Mu and Viswanath (2018) on word embeddings, demonstrating that similar bias removal techniques have been successful in other NLP domains.


## 5. Results in Context

**Main Results:**

* **Toxicity Removal:** Mean-centring effectively reduces toxicity in generated text, comparable to ActAdd (Turner et al., 2023).
* **Genre Steering:** Mean-centring successfully steers the genre of generated stories, increasing the frequency of genre-specific words.
* **Function Vector Extraction:** Mean-centring improves the accuracy of function vector extraction for certain tasks.

**Comparison with Existing Literature:**

* **Toxicity Removal:** The results are comparable to ActAdd (Turner et al., 2023), suggesting that mean-centring is a viable alternative for toxicity reduction.
* **Genre Steering:** The paper demonstrates a novel application of activation steering, extending the capabilities of existing methods beyond tasks like toxicity removal.
* **Function Vector Extraction:** The results extend the work of Todd et al. (2023) by showing that mean-centring can improve the accuracy of function vector extraction.


## 6. Discussion and Related Work

**Situating the Work:** The authors position their work within the broader context of activation steering and representation engineering. They highlight the limitations of existing methods, such as the need for counterbalancing concepts or computationally expensive techniques. They emphasize that mean-centring offers a simpler and more versatile approach that can be applied to a wider range of tasks.

**Key Papers Cited:**

* **Turner et al. (2023):**  This paper is frequently cited as a key work in activation steering, providing a baseline for comparison in the toxicity removal experiments.
* **Todd et al. (2023):** This paper introduces the concept of function vectors, which the authors build upon in their function vector extraction experiments.
* **Zou et al. (2023):** This paper discusses representation engineering, a related concept to activation steering, and is cited in the context of potential connections to mean-centring.
* **Mu and Viswanath (2018):** This paper provides inspiration for the mean-centring method, demonstrating the effectiveness of bias removal in word embeddings.

**Highlighting Novelty:** The authors use these citations to emphasize the simplicity and versatility of mean-centring compared to existing methods. They argue that their approach can be easily applied to a wider range of tasks, making activation steering more accessible to researchers.


## 7. Future Work and Open Questions

**Areas for Further Research:**

* **Investigating the link between anisotropy and improvements in accuracy:** The authors suggest that the effectiveness of mean-centring might be related to the degree of anisotropy in the language model.
* **Investigating other relevant factors that predict the success of mean-centring:** The authors acknowledge that other factors might influence the effectiveness of their method.
* **Investigating the extent to which accounting for other structures in activation geometries (e.g., clustering) could lead to further improvements to steering:** This suggestion builds upon the work of Cai et al. (2021).

**Supporting Citations:**

* **Cai et al. (2021):** This paper provides evidence for other structures in activation geometries, motivating the suggestion to explore their impact on steering.


## 8. Critical Analysis of Citation Usage

**Effectiveness of Citation Usage:** The authors generally use citations effectively to support their claims and findings. They provide a clear context for their work by referencing key papers in activation steering, representation engineering, and related areas.

**Areas for Improvement:**

* **More Diverse Citation Sources:** While the authors cite a good range of papers, they could potentially benefit from including more diverse sources, such as works from the social sciences or humanities, to address the broader societal implications of their work.
* **Explicit Connections to Safety and Ethics:** Given the focus on mitigating toxicity, the authors could strengthen their discussion of safety and ethical considerations by including more citations from works that explicitly address these issues in LLMs.

**Potential Biases:** The authors primarily rely on citations from the deep learning and NLP communities, which is understandable given the technical nature of their work. However, a more diverse range of citations could enhance the paper's impact and contribute to a more nuanced understanding of the broader implications of their findings.


## 9. Final Summary

**Contribution to the Field:** The paper introduces a novel and simple technique called mean-centring for improving activation steering in LLMs. It demonstrates the effectiveness of this method across various tasks, including toxicity removal, genre steering, and function vector extraction. The proposed method offers a more versatile and accessible approach to activation steering, potentially expanding its applicability in a wider range of applications.

**Influential Cited Works:**

* **Turner et al. (2023):** This paper is a key reference for activation steering, providing a baseline for comparison in the toxicity removal experiments.
* **Todd et al. (2023):** This paper introduces the concept of function vectors, which the authors build upon in their function vector extraction experiments.
* **Mu and Viswanath (2018):** This paper provides inspiration for the mean-centring method, demonstrating the effectiveness of bias removal in word embeddings.
* **Ethayarajh (2019) and Cai et al. (2021):** These papers introduce the concept of anisotropy in language model activations, which is a key factor motivating the mean-centring approach.

**Assessment of Literature Integration:** The paper effectively integrates existing literature to support its claims and findings. It provides a clear context for its work by referencing key papers in activation steering and related areas. The authors effectively use citations to highlight the novelty and importance of their own work, demonstrating a strong understanding of the current research landscape.


I hope this comprehensive analysis, presented in Markdown format, is helpful in understanding the paper and its relationship to the broader research context. Please let me know if you have any further questions or if you'd like me to refine any specific aspect of the analysis.  
