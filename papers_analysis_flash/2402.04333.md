## Analysis of "LESS: Selecting Influential Data for Targeted Instruction Tuning"

**1. Introduction:**

- **Title:** LESS: Selecting Influential Data for Targeted Instruction Tuning
- **Authors:** Mengzhou Xia, Sadhika Malladi, Suchin Gururangan, Sanjeev Arora, Danqi Chen
- **Publication Date:** 2024 (Proceedings of the 41st International Conference on Machine Learning)
- **Objective:** The paper proposes LESS, an optimizer-aware and efficient algorithm for selecting influential instruction data to effectively train large language models (LLMs) for specific capabilities, addressing the challenge of targeted instruction tuning.
- **References:** The paper cites a total of 68 references.

**2. Section-by-Section Analysis with Citation Extraction:**

**a. Introduction:**

- **Key Points:**
    - Instruction tuning has significantly improved LLMs' ability to follow instructions, leading to versatile chatbots.
    - Existing instruction tuning datasets are diverse but lack focus on specific capabilities.
    - Training LLMs on mixed datasets can hinder the development of specific skills.
    - Targeted instruction tuning aims to select relevant data for specific capabilities using only a few examples.
- **Citations:**
    - **Claim:** Instruction tuning has made large language models (LLMs) adept at following human instructions.
        - **Citation:** (Ouyang et al., 2022)
        - **Relevance:** This citation introduces the concept of instruction tuning and its impact on LLMs.
    - **Claim:** Recent efforts curating highly diverse and wide-ranging instruction tuning datasets induce remarkably strong generalization even from a small number of examples.
        - **Citation:** (Taori et al., 2023; Wang et al.; Mukherjee et al., 2023; Xu et al., 2023, inter alia)
        - **Relevance:** This citation highlights the availability of diverse instruction tuning datasets and their potential for generalization.
    - **Claim:** Training LLMs with mixed instruction tuning datasets can hinder the development of these specific capabilities.
        - **Citation:** (Wang et al., 2023b)
        - **Relevance:** This citation introduces the problem of mixed datasets hindering specific skill development.

**b. Related Work:**

- **Key Points:**
    - The paper discusses related work in curating high-quality instruction tuning data, coreset selection, and data attribution.
    - It highlights the importance of data quality and diversity for instruction tuning.
    - The authors differentiate their work from existing coreset selection methods by focusing on transfer learning.
    - They compare their influence formulation to existing influence functions and data attribution methods.
- **Citations:**
    - **Claim:** Curating high-quality instruction tuning data can dramatically improve base LLMs.
        - **Citation:** (Wang et al., 2022; Sanh et al., 2022; Wei et al., 2022b; Longpre et al., 2023; Taori et al., 2023; Conover et al., 2023; Köpf et al., 2023; Xu et al., 2023; Mukherjee et al., 2023; Zhou et al., 2023; Ding et al., 2023)
        - **Relevance:** This citation provides a broad overview of research on instruction tuning datasets.
    - **Claim:** Data selection has been viewed as a coreset selection problem.
        - **Citation:** (Phillips, 2017)
        - **Relevance:** This citation introduces the concept of coreset selection and its relevance to data selection.
    - **Claim:** Our work involves transfer learning, which differentiates it from existing coreset selection methods.
        - **Citation:** (Gururangan et al., 2020; Chen et al., 2023b; Xie et al., 2023b; Mirzasoleiman et al., 2020; Wang et al., 2020; Yu et al., 2020b; Killamsetty et al., 2021a)
        - **Relevance:** This citation highlights the distinction between in-domain coreset selection and transfer learning.
    - **Claim:** Our influence formulation has been used in identifying mislabeled examples, analyzing memorization effects, and deriving various interpretability insights.
        - **Citation:** (Pruthi et al., 2020; Feldman & Zhang, 2020; Madsen et al., 2022)
        - **Relevance:** This citation demonstrates the application of influence formulations in various areas.

**c. Preliminaries: Influence Formulation:**

- **Key Points:**
    - The paper restates the influence formulation from Pruthi et al. (2020) for estimating the influence of a training datapoint on held-out data.
    - It defines per-step influence and trajectory influence.
    - The authors discuss the limitations of using influence for data selection with SGD and highlight the need for an optimizer-aware approach.
- **Citations:**
    - **Claim:** Consider a model Ot at time step t trained on the loss l(.; 0t).
        - **Citation:** (Pruthi et al., 2020)
        - **Relevance:** This citation introduces the influence formulation used in the paper.
    - **Claim:** We discuss in Section 7 how this formulation of influence is distinct from influence functions.
        - **Citation:** (Koh & Liang, 2017)
        - **Relevance:** This citation clarifies the distinction between the influence formulation used in the paper and influence functions.

**d. LESS: Estimating the Influence of Instructions:**

- **Key Points:**
    - The authors adapt the influence formulation to work with the Adam optimizer and variable-length instruction data.
    - They address the issue of sequence-level gradients favoring shorter instructions.
    - They introduce the concept of Adam influence, which normalizes gradient features and uses cosine similarity for influence estimation.
- **Citations:**
    - **Claim:** LLMs are traditionally tuned using Adam.
        - **Citation:** (Kingma & Ba, 2015)
        - **Relevance:** This citation highlights the common use of Adam for fine-tuning LLMs.
    - **Claim:** We discuss learning rate schedules and batches in Appendix E.
        - **Citation:** (Appendix E)
        - **Relevance:** This citation indicates that the authors provide further details on learning rate schedules and batches in the appendix.

**e. LESS: Computing Influences Efficiently:**

- **Key Points:**
    - The authors propose a computationally efficient approach for estimating influences using LORA and random projections.
    - They describe the steps involved in LESS, including warmup training with LORA, gradient feature computation, and data selection.
- **Citations:**
    - **Claim:** We use LORA (Hu et al., 2021) to efficiently perform the warmup training.
        - **Citation:** (Hu et al., 2021)
        - **Relevance:** This citation introduces LORA, a parameter-efficient fine-tuning method used for warmup training.
    - **Claim:** We apply these techniques to ∇l(z'; 0) for validation datapoints z' and to Γ(z, 0) for training datapoints z.
        - **Citation:** (Johnson & Lindenstrauss, 1984; Park et al., 2023)
        - **Relevance:** This citation introduces random projections, a technique used for dimensionality reduction.

**f. Experiments:**

- **Key Points:**
    - The authors evaluate LESS on three diverse downstream datasets: MMLU, TYDIQA, and BBH.
    - They compare LESS to several baselines, including random selection, BM25, DSIR, and RDS.
    - They demonstrate that LESS consistently outperforms baselines and often achieves better performance than training on the full dataset using only 5% of the data selected by LESS.
    - They show that data selected using a smaller model can be effectively used for training larger models.
- **Citations:**
    - **Claim:** We evaluate our approach on three diverse downstream datasets—MMLU (Hendrycks et al., 2020), TYDIQA (Clark et al., 2020), and BBH (Suzgun et al., 2023).
        - **Citation:** (Hendrycks et al., 2020; Clark et al., 2020; Suzgun et al., 2023)
        - **Relevance:** This citation introduces the evaluation datasets used in the paper.
    - **Claim:** We compare LESS with a several baselines (see more details in Appendix C).
        - **Citation:** (Appendix C)
        - **Relevance:** This citation indicates that the authors provide further details on the baselines used in the experiments in the appendix.
    - **Claim:** We use pre-trained LLAMA-2-7B and LLAMA-2-7B-CHAT as selection models to create a gradient datastore for selecting data.
        - **Citation:** (Appendix D.2)
        - **Relevance:** This citation indicates that the authors provide further details on the ablations using pre-trained models in the appendix.

**g. Analysis:**

- **Key Points:**
    - The authors analyze the computational cost of LESS and explore the impact of different design choices.
    - They provide a qualitative analysis showing that LESS selects data that aligns with the reasoning capabilities needed for the target task.
    - They discuss the limitations of LESS, including the need for warmup training, the use of average gradients over completion tokens, and the potential for negative transfer.
    - They compare LESS to the datamodels framework and kernel behavior.
- **Citations:**
    - **Claim:** We use LORA (Hu et al., 2021) to reduce the number of trainable parameters and accelerate the inner products in Definition 3.1.
        - **Citation:** (Hu et al., 2021)
        - **Relevance:** This citation highlights the use of LORA for reducing computational cost.
    - **Claim:** We discuss in Section 7 how this formulation of influence is distinct from influence functions.
        - **Citation:** (Koh & Liang, 2017)
        - **Relevance:** This citation clarifies the distinction between the influence formulation used in the paper and influence functions.
    - **Claim:** Concurrent work in Engstrom et al. (2024) applies the datamodels framework (Ilyas et al., 2022) to select pre-training data to induce strong performance on target downstream tasks.
        - **Citation:** (Engstrom et al., 2024; Ilyas et al., 2022)
        - **Relevance:** This citation introduces the datamodels framework and its application to data selection.

**h. Discussion and Future Work:**

- **Key Points:**
    - The authors discuss the potential of LESS for test-time adaptation and the use of alternative metrics for data selection.
    - They highlight the importance of investigating the utility of gradient features for data selection.
    - They acknowledge the limitations of LESS, including the need for warmup training, the use of average gradients over completion tokens, and the potential for negative transfer.
- **Citations:**
    - **Claim:** Our experiments and concurrent findings in Engstrom et al. (2024) may prompt further investigation of the utility of gradient features as opposed to surface-form cues in data selection.
        - **Citation:** (Engstrom et al., 2024)
        - **Relevance:** This citation highlights the importance of investigating the utility of gradient features for data selection.

**3. Key Insights and Supporting Literature:**

- **Key Insight:** LESS effectively selects influential instruction data for targeted instruction tuning, often outperforming training on the full dataset using only 5% of the selected data.
    - **Supporting Citations:** (Pruthi et al., 2020; Kingma & Ba, 2015; Hu et al., 2021; Johnson & Lindenstrauss, 1984; Park et al., 2023)
    - **Explanation:** The authors build upon the influence formulation from Pruthi et al. (2020) and adapt it to work with the Adam optimizer (Kingma & Ba, 2015). They leverage LORA (Hu et al., 2021) and random projections (Johnson & Lindenstrauss, 1984; Park et al., 2023) to efficiently compute and store gradient features, enabling efficient data selection.
- **Key Insight:** Data selected using a smaller model can be effectively used for training larger models, demonstrating the transferability of LESS.
    - **Supporting Citations:** (Xie et al., 2023a; Engstrom et al., 2024)
    - **Explanation:** This finding aligns with previous research showing that smaller models can effectively select data for larger models during pre-training (Xie et al., 2023a) and in-context learning (Wang et al., 2023a).

**4. Experimental Methodology and Its Foundations:**

- **Experimental Setup:**
    - The authors evaluate LESS on three diverse downstream datasets: MMLU, TYDIQA, and BBH.
    - They use LLAMA-2-7B, LLAMA-2-13B, and MISTRAL-7B as base models for training and data selection.
    - They compare LESS to several baselines, including random selection, BM25, DSIR, and RDS.
    - They conduct experiments with different data percentages (5% and 100%) and model sizes.
- **Foundations:**
    - The authors use LORA (Hu et al., 2021) for parameter-efficient fine-tuning and random projections (Johnson & Lindenstrauss, 1984; Park et al., 2023) for dimensionality reduction.
    - They adapt the influence formulation from Pruthi et al. (2020) to work with the Adam optimizer (Kingma & Ba, 2015).
- **Novel Aspects:**
    - The authors introduce an optimizer-aware influence formulation for data selection, specifically for the Adam optimizer.
    - They address the issue of sequence-level gradients favoring shorter instructions by normalizing gradient features and using cosine similarity for influence estimation.
    - They propose a computationally efficient approach for estimating influences using LORA and random projections.
    - The authors justify these novel approaches by citing relevant works and providing empirical evidence through their experiments.

**5. Results in Context:**

- **Main Results:**
    - LESS consistently outperforms baselines and often achieves better performance than training on the full dataset using only 5% of the selected data.
    - Data selected using a smaller model can be effectively used for training larger models.
- **Comparison with Existing Literature:**
    - The authors compare their results with existing data selection methods, including random selection, BM25, DSIR, and RDS.
    - They demonstrate that LESS consistently outperforms these baselines.
- **Confirmation, Contradiction, or Extension:**
    - The authors' results confirm the importance of data quality and diversity for instruction tuning, as highlighted in previous work (Wang et al., 2022; Sanh et al., 2022; Wei et al., 2022b; Longpre et al., 2023; Taori et al., 2023; Conover et al., 2023; Köpf et al., 2023; Xu et al., 2023; Mukherjee et al., 2023; Zhou et al., 2023; Ding et al., 2023).
    - They extend existing research on data selection by introducing an optimizer-aware approach and demonstrating its effectiveness for targeted instruction tuning.

**6. Discussion and Related Work:**

- **Situating the Work:**
    - The authors situate their work within the broader context of instruction tuning, highlighting the importance of data quality and diversity.
    - They differentiate their work from existing coreset selection methods by focusing on transfer learning.
    - They compare their influence formulation to existing influence functions and data attribution methods.
- **Key Papers Cited:**
    - (Ouyang et al., 2022)
    - (Taori et al., 2023; Wang et al.; Mukherjee et al., 2023; Xu et al., 2023, inter alia)
    - (Wang et al., 2023b)
    - (Phillips, 2017)
    - (Gururangan et al., 2020; Chen et al., 2023b; Xie et al., 2023b; Mirzasoleiman et al., 2020; Wang et al., 2020; Yu et al., 2020b; Killamsetty et al., 2021a)
    - (Pruthi et al., 2020; Feldman & Zhang, 2020; Madsen et al., 2022)
    - (Koh & Liang, 2017)
    - (Kingma & Ba, 2015)
    - (Hu et al., 2021)
    - (Johnson & Lindenstrauss, 1984; Park et al., 2023)
    - (Xie et al., 2023a; Engstrom et al., 2024)
    - (Hendrycks et al., 2020; Clark et al., 2020; Suzgun et al., 2023)
    - (Ilyas et al., 2022)
- **Novelty and Importance:**
    - The authors highlight the novelty of their optimizer-aware influence formulation and its effectiveness for targeted instruction tuning.
    - They emphasize the importance of their work for addressing the challenge of selecting relevant data for specific capabilities in LLMs.

**7. Future Work and Open Questions:**

- **Areas for Further Research:**
    - Exploring the potential of LESS for test-time adaptation.
    - Investigating the use of alternative metrics for data selection, such as toxicity and harmfulness.
    - Further investigating the utility of gradient features for data selection.
    - Exploring the optimal threshold for discarding data during data selection.
    - Investigating the impact of sequence length on gradient features and exploring potential solutions for token-wise data selection.
- **Citations:**
    - (Engstrom et al., 2024)
    - (Arora et al., 2019; Yu et al., 2020a; Wei et al., 2022a; Malladi et al., 2023)

**8. Critical Analysis of Citation Usage:**

- **Effectiveness:** The authors effectively use citations to support their arguments and findings. They provide a comprehensive overview of related work and clearly differentiate their approach from existing methods.
- **Areas for Improvement:**
    - The authors could have provided more citations to support their claims about the limitations of LESS, such as the need for warmup training and the use of average gradients over completion tokens.
    - They could have included more citations to support their discussion of kernel behavior and its relationship to instruction tuning.
- **Potential Biases:**
    - The authors primarily cite works from top conferences and journals, which may reflect a bias towards mainstream research.
    - They could have included more citations from less prominent publications or preprints to provide a more diverse perspective on the field.

**9. Final Summary:**

- **Contribution:** The paper makes a significant contribution to the field of instruction tuning by introducing LESS, an optimizer-aware and efficient algorithm for selecting influential instruction data for targeted instruction tuning.
- **Influential Works:**
    - (Pruthi et al., 2020)
    - (Kingma & Ba, 2015)
    - (Hu et al., 2021)
    - (Johnson & Lindenstrauss, 1984)
    - (Park et al., 2023)
- **Integration of Existing Literature:** The paper effectively integrates existing literature to support its claims and findings. It provides a comprehensive overview of related work, clearly differentiates its approach from existing methods, and cites relevant works to justify its novel approaches.

Overall, the paper presents a valuable contribution to the field of instruction tuning by addressing the challenge of targeted instruction tuning. The authors' proposed LESS algorithm is effective, efficient, and transferable, demonstrating its potential for improving the performance of LLMs in real-world applications. The paper's thorough analysis and clear presentation of its findings make it a valuable resource for researchers working in this area.
