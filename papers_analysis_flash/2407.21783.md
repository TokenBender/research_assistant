## Analysis of "The Llama 3 Herd of Models"

**1. Introduction:**

- **Title:** The Llama 3 Herd of Models
- **Authors:** Llama Team, AI @ Meta
- **Publication Date:** July 23, 2024
- **Objective:** This paper introduces a new set of foundation models called Llama 3, designed to support multilinguality, coding, reasoning, and tool usage. The authors aim to demonstrate the comparable quality of Llama 3 to leading language models like GPT-4 across various tasks.
- **Number of References:** 100

**2. Section-by-Section Analysis with Citation Extraction:**

**2.1 Introduction:**

- **Key Points:**
    - Foundation models are general models of language, vision, speech, or other modalities designed for various AI tasks.
    - The development of foundation models involves pre-training and post-training stages.
    - Llama 3 is a new set of foundation models that natively support multilinguality, coding, reasoning, and tool usage.
    - The authors highlight three key levers in developing high-quality foundation models: data, scale, and managing complexity.
- **Significant Citations:**
    - **Claim:** Llama 3 improves upon prior versions of Llama in terms of data quantity and quality.
    - **Citation:** Touvron et al., 2023a,b
    - **Explanation:** This citation refers to previous work by the authors on Llama 1 and Llama 2, highlighting the advancements made in Llama 3.
    - **Claim:** Llama 3 is trained at a larger scale than previous Llama models.
    - **Citation:** Touvron et al., 2023b
    - **Explanation:** This citation provides context for the scaling improvements in Llama 3 compared to its predecessors.

**2.2 General Overview:**

- **Key Points:**
    - Llama 3 models are trained in two stages: language model pre-training and language model post-training.
    - Pre-training involves training the model on a large multilingual text corpus to learn the structure of language and acquire knowledge about the world.
    - Post-training aligns the model with human feedback to improve specific capabilities like coding, reasoning, and tool usage.
    - The authors emphasize the importance of managing complexity in model development, opting for a standard dense Transformer architecture and a relatively simple post-training procedure.
- **Significant Citations:**
    - **Claim:** The authors use a standard dense Transformer architecture for Llama 3.
    - **Citation:** Vaswani et al., 2017
    - **Explanation:** This citation refers to the seminal work on the Transformer architecture, which forms the basis for Llama 3.
    - **Claim:** The authors use a simple post-training procedure based on supervised finetuning, rejection sampling, and direct preference optimization.
    - **Citation:** Ouyang et al., 2022; Schulman et al., 2017; Rafailov et al., 2023
    - **Explanation:** These citations highlight the specific post-training techniques employed by the authors, contrasting them with more complex reinforcement learning algorithms.

**2.3 Pre-Training:**

- **Key Points:**
    - The authors describe the process of curating and filtering a large-scale training corpus for Llama 3.
    - They discuss the importance of data quality and diversity, highlighting the use of various techniques like de-duplication, heuristic filtering, and model-based quality filtering.
    - The authors explain their approach to determining the optimal data mix for pre-training, using knowledge classification and scaling law experiments.
    - They also discuss the use of annealing to improve model performance on specific tasks.
- **Significant Citations:**
    - **Claim:** The authors use a custom parser to extract high-quality text from HTML content.
    - **Citation:** Broder, 1997
    - **Explanation:** This citation refers to the MinHash algorithm used for document-level de-duplication.
    - **Claim:** The authors use a Kullback-Leibler divergence to filter out documents containing excessive numbers of outlier tokens.
    - **Citation:** Raffel et al., 2020
    - **Explanation:** This citation refers to the use of "dirty word" counting for filtering adult content.
    - **Claim:** The authors use fasttext and Roberta-based classifiers for model-based quality filtering.
    - **Citation:** Joulin et al., 2017; Liu et al., 2019a; Touvron et al., 2023a; Sanh et al., 2019
    - **Explanation:** These citations highlight the specific classifiers used for quality filtering, demonstrating the authors' reliance on existing work in this area.
    - **Claim:** The authors use annealing to improve model performance on specific tasks.
    - **Citation:** Li et al., 2024b; OpenAI, 2023a; Cobbe et al., 2021; Hendrycks et al., 2021b; Blakeney et al., 2024
    - **Explanation:** These citations demonstrate the authors' awareness of existing research on annealing and its application in improving model performance.

**2.4 Model Architecture:**

- **Key Points:**
    - Llama 3 uses a standard dense Transformer architecture with minor modifications.
    - The authors highlight the use of grouped query attention and an attention mask to improve inference speed and reduce the size of key-value caches.
    - They discuss the choice of vocabulary size and the use of ROPE for positional embeddings.
- **Significant Citations:**
    - **Claim:** Llama 3 uses a standard dense Transformer architecture.
    - **Citation:** Vaswani et al., 2017
    - **Explanation:** This citation reinforces the authors' reliance on the Transformer architecture as a foundation for Llama 3.
    - **Claim:** The authors use grouped query attention to improve inference speed.
    - **Citation:** Ainslie et al., 2023
    - **Explanation:** This citation refers to the GQA technique, demonstrating the authors' awareness of existing work in this area.
    - **Claim:** The authors use ROPE for positional embeddings.
    - **Citation:** Xiong et al., 2023
    - **Explanation:** This citation highlights the specific technique used for positional embeddings, demonstrating the authors' awareness of existing research in this area.

**2.5 Scaling Laws:**

- **Key Points:**
    - The authors use scaling laws to determine the optimal model size for Llama 3 given their pre-training compute budget.
    - They describe a two-stage methodology for developing scaling laws that accurately predict downstream benchmark performance.
    - The authors highlight the importance of considering the trade-off between model size and training tokens.
- **Significant Citations:**
    - **Claim:** The authors use scaling laws to determine the optimal model size.
    - **Citation:** Hoffmann et al., 2022; Kaplan et al., 2020
    - **Explanation:** These citations highlight the authors' reliance on existing research on scaling laws in foundation model development.
    - **Claim:** The authors use a two-stage methodology for developing scaling laws.
    - **Citation:** Wei et al., 2022b
    - **Explanation:** This citation refers to the authors' previous work on scaling laws, demonstrating their expertise in this area.

**2.6 Infrastructure, Scaling, and Efficiency:**

- **Key Points:**
    - The authors describe the hardware and infrastructure used for training Llama 3 405B at scale.
    - They discuss the use of Meta's AI Research SuperCluster and production clusters for training.
    - The authors highlight the importance of network topology, load balancing, and congestion control in achieving high training efficiency.
    - They describe the use of 4D parallelism to shard the model and distribute computation across multiple GPUs.
    - The authors discuss the use of NCCLX for collective communication and its advantages over NCCL.
- **Significant Citations:**
    - **Claim:** The authors use Meta's AI Research SuperCluster for training Llama 1 and Llama 2.
    - **Citation:** Lee and Sengupta, 2022
    - **Explanation:** This citation highlights the authors' reliance on Meta's infrastructure for training large language models.
    - **Claim:** The authors use Meta's production clusters for training Llama 3.
    - **Citation:** Lee et al., 2024
    - **Explanation:** This citation provides context for the authors' shift to production clusters for training Llama 3.
    - **Claim:** The authors use RDMA over Converged Ethernet for network communication.
    - **Citation:** Gangidi et al., 2024
    - **Explanation:** This citation highlights the authors' reliance on specific network technologies for training Llama 3.
    - **Claim:** The authors use 4D parallelism for model scaling.
    - **Citation:** Krizhevsky et al., 2012; Shoeybi et al., 2019; Korthikanti et al., 2023; Huang et al., 2019; Narayanan et al., 2021; Lamy-Poirier, 2023; Liu et al., 2023a; Rajbhandari et al., 2020; Ren et al., 2021; Zhao et al., 2023b
    - **Explanation:** These citations demonstrate the authors' awareness of existing research on various parallelism techniques used for training large language models.

**2.7 Training Recipe:**

- **Key Points:**
    - The authors describe the training recipe for Llama 3 405B, which involves three stages: initial pre-training, long-context pre-training, and annealing.
    - They discuss the use of AdamW optimizer, a cosine learning rate schedule, and a gradual increase in batch size during initial pre-training.
    - The authors highlight the importance of adjusting the data mix during training to improve model performance on specific tasks.
    - They describe the long-context pre-training stage, where the model is trained on longer sequences to support a larger context window.
    - The authors discuss the use of annealing to produce the final pre-trained model.
- **Significant Citations:**
    - **Claim:** The authors use AdamW optimizer for training.
    - **Citation:** Loshchilov et al., 2017
    - **Explanation:** This citation highlights the authors' reliance on a specific optimizer for training Llama 3.
    - **Claim:** The authors use a cosine learning rate schedule for training.
    - **Citation:**  Loshchilov et al., 2017
    - **Explanation:** This citation highlights the authors' reliance on a specific learning rate schedule for training Llama 3.
    - **Claim:** The authors use annealing to improve model performance on specific tasks.
    - **Citation:** Li et al., 2024b; OpenAI, 2023a; Cobbe et al., 2021; Hendrycks et al., 2021b; Blakeney et al., 2024
    - **Explanation:** These citations demonstrate the authors' awareness of existing research on annealing and its application in improving model performance.

**2.8 Post-Training:**

- **Key Points:**
    - The authors describe the post-training approach for Llama 3, which involves multiple rounds of supervised finetuning (SFT) and direct preference optimization (DPO).
    - They discuss the use of a reward model to guide the post-training process.
    - The authors highlight the importance of data composition in post-training, describing the use of human annotations, synthetic data, and rejection sampling.
    - They discuss the use of a chat dialog format for human-AI interaction and the importance of quality control in post-training data.
- **Significant Citations:**
    - **Claim:** The authors use supervised finetuning for post-training.
    - **Citation:** Ouyang et al., 2022; Rafailov et al., 2024; Wei et al., 2022a; Sanh et al., 2022; Wang et al., 2022b
    - **Explanation:** These citations highlight the authors' reliance on existing research on supervised finetuning in foundation model development.
    - **Claim:** The authors use direct preference optimization for post-training.
    - **Citation:** Rafailov et al., 2024; Schulman et al., 2017; Zhou et al., 2023
    - **Explanation:** These citations highlight the authors' reliance on existing research on direct preference optimization in foundation model development.
    - **Claim:** The authors use rejection sampling for post-training.
    - **Citation:** Bai et al., 2022; Kwon et al., 2023
    - **Explanation:** These citations highlight the authors' reliance on existing research on rejection sampling in foundation model development.

**2.9 Capabilities:**

- **Key Points:**
    - The authors discuss the specific capabilities of Llama 3, including code generation, multilinguality, math and reasoning, long context, tool use, factuality, and steerability.
    - They describe the use of expert training, synthetic data generation, and system prompt steering to improve code generation capabilities.
    - The authors highlight the importance of collecting high-quality multilingual data and addressing specific challenges in multilingual language steering.
    - They discuss the challenges in training models for math and reasoning, including the lack of prompts, the lack of ground truth chains of thought, and the issue of incorrect intermediate steps.
    - The authors describe their approach to training models for long context, including the use of hierarchical summarization and code reasoning.
    - They discuss the importance of tool use in expanding the capabilities of LLMs and describe their approach to training models for tool use.
    - The authors highlight the challenge of hallucinations in LLMs and describe their approach to improving factuality.
    - They discuss the importance of steerability in foundation models and describe their approach to improving steerability.
- **Significant Citations:**
    - **Claim:** The authors use expert training to improve code generation capabilities.
    - **Citation:** Chen et al., 2021; Gururangan et al., 2020; Rozière et al., 2023
    - **Explanation:** These citations highlight the authors' reliance on existing research on expert training in foundation model development.
    - **Claim:** The authors use synthetic data generation to improve code generation capabilities.
    - **Citation:** DeepSeek-AI et al., 2024; Chen et al., 2023; Wei et al., 2024b
    - **Explanation:** These citations highlight the authors' reliance on existing research on synthetic data generation in foundation model development.
    - **Claim:** The authors use system prompt steering to improve code generation capabilities.
    - **Citation:**  Zhou et al., 2023
    - **Explanation:** This citation highlights the authors' reliance on existing research on system prompt steering in foundation model development.
    - **Claim:** The authors use a multilingual expert to improve multilingual capabilities.
    - **Citation:** Hardalov et al., 2020; Wu et al., 2023; Prokopidis et al., 2016; Tiedemann, 2012; Wei et al., 2022a; Bizzoni et al., 2020; Muennighoff et al., 2023; Wang et al., 2022a; Shi et al., 2022
    - **Explanation:** These citations highlight the authors' reliance on existing research on multilingual data collection and training in foundation model development.
    - **Claim:** The authors address the challenge of incorrect intermediate steps in math and reasoning.
    - **Citation:** Cobbe et al., 2021; Uesato et al., 2022; Lightman et al., 2023; Wang et al., 2023a; Gao et al., 2023; Chen et al., 2022; Gou et al., 2023; Yu et al., 2023; Yue et al., 2023; Luo et al., 2023; Mitra et al., 2024; Shao et al., 2024; Yue et al., 2024b; Wei et al., 2022c; Zelikman et al., 2022; Didolkar et al., 2024; Li et al., 2024a; Lightman et al., 2023; Wang et al., 2023a; Xie et al., 2024; Gou et al., 2023; An et al., 2023b; Welleck et al., 2022; Madaan et al., 2024a
    - **Explanation:** These citations highlight the authors' awareness of existing research on the challenges of training models for math and reasoning and the various techniques used to address these challenges.
    - **Claim:** The authors use hierarchical summarization for long context.
    - **Citation:** Shaham et al., 2023; Kamradt, 2023; Zhang et al., 2024
    - **Explanation:** These citations highlight the authors' reliance on existing research on long context in foundation model development.
    - **Claim:** The authors use code reasoning for long context.
    - **Citation:**  Zhang et al., 2024
    - **Explanation:** This citation highlights the authors' reliance on existing research on code reasoning in foundation model development.
    - **Claim:** The authors use tools to expand the capabilities of LLMs.
    - **Citation:** Nakano et al., 2021; Thoppilan et al., 2022; Parisi et al., 2022; Gao et al., 2023; Mialon et al., 2023a; Schick et al., 2024
    - **Explanation:** These citations highlight the authors' awareness of existing research on tool use in foundation model development.
    - **Claim:** The authors use a hallucination-first approach to improve factuality.
    - **Citation:** Gekhman et al., 2024; Mielke et al., 2020
    - **Explanation:** These citations highlight the authors' reliance on existing research on factuality in foundation model development.
    - **Claim:** The authors use system prompts to improve steerability.
    - **Citation:**  Touvron et al., 2023b
    - **Explanation:** This citation highlights the authors' reliance on existing research on system prompts in foundation model development.

**2.10 Safety:**

- **Key Points:**
    - The authors discuss the importance of safety in foundation models and describe their approach to ensuring safe and responsible use of Llama 3.
    - They highlight the use of various techniques for safety pre-training, including data filtering, discoverable memorization, and safety finetuning.
    - The authors describe the use of adversarial and borderline prompts for safety finetuning.
    - They discuss the use of synthetic data generation and the importance of balancing safety and helpfulness in training.
    - The authors describe the use of a system-level safety classifier, Llama Guard, to mitigate risks across various capabilities.
    - They discuss the use of prompt-based system guards, Prompt Guard and Code Shield, to detect prompt attacks and insecure code.
    - The authors highlight the importance of child safety and describe their approach to assessing and mitigating child safety risks.
- **Significant Citations:**
    - **Claim:** The authors use a variety of filters for safety pre-training.
    - **Citation:** Carlini et al., 2022; Nasr et al., 2023
    - **Explanation:** These citations highlight the authors' reliance on existing research on safety pre-training in foundation model development.
    - **Claim:** The authors use adversarial and borderline prompts for safety finetuning.
    - **Citation:**  Touvron et al., 2023b
    - **Explanation:** This citation highlights the authors' reliance on existing research on safety finetuning in foundation model development.
    - **Claim:** The authors use synthetic data generation for safety finetuning.
    - **Citation:** Samvelyan et al., 2024; Ippolito et al., 2023; Kassem et al., 2024
    - **Explanation:** These citations highlight the authors' reliance on existing research on synthetic data generation in foundation model development.
    - **Claim:** The authors use a system-level safety classifier, Llama Guard.
    - **Citation:**  Llama-Team, 2024
    - **Explanation:** This citation highlights the authors' reliance on existing research on system-level safety classifiers in foundation model development.
    - **Claim:** The authors use prompt-based system guards, Prompt Guard and Code Shield.
    - **Citation:**  Schick et al., 2024; Singh et al., 2024
    - **Explanation:** These citations highlight the authors' reliance on existing research on prompt-based system guards in foundation model development.

**2.11 Vision Experiments:**

- **Key Points:**
    - The authors describe their approach to incorporating visual-recognition capabilities into Llama 3 via a compositional approach.
    - They discuss the use of a pre-trained image encoder and a set of cross-attention layers to integrate the image encoder with the pre-trained language model.
    - The authors describe the use of a video adapter to learn temporal information from videos.
    - They highlight the advantages of a compositional approach, including parallelization of development, avoidance of complexities in joint pre-training, and improved efficiency during inference.
- **Significant Citations:**
    - **Claim:** The authors use a pre-trained image encoder for visual-recognition.
    - **Citation:** Xu et al., 2023
    - **Explanation:** This citation highlights the authors' reliance on existing research on pre-trained image encoders in foundation model development.
    - **Claim:** The authors use cross-attention layers to integrate the image encoder with the pre-trained language model.
    - **Citation:** Alayrac et al., 2022
    - **Explanation:** This citation highlights the authors' reliance on existing research on cross-attention layers in foundation model development.

**2.12 Speech Experiments:**

- **Key Points:**
    - The authors describe their approach to incorporating speech capabilities into Llama 3 via a compositional approach.
    - They discuss the use of a speech encoder and an adapter to process speech signals.
    - The authors highlight the use of a system prompt to enable different modes of operation for speech understanding.
    - They describe the use of a streaming text-to-speech (TTS) system for speech generation.
- **Significant Citations:**
    - **Claim:** The authors use a Conformer model for speech encoding.
    - **Citation:** Gulati et al., 2020
    - **Explanation:** This citation highlights the authors' reliance on existing research on Conformer models for speech encoding.
    - **Claim:** The authors use a Transformer-based Prosody model for speech generation.
    - **Citation:** Radford et al., 2021; Devlin et al., 2018; Dong et al., 2019; Raffel et al., 2020; Guo et al., 2023
    - **Explanation:** These citations highlight the authors' reliance on existing research on Transformer-based Prosody models for speech generation.

**3. Key Insights and Supporting Literature:**

- **Insight:** Llama 3 demonstrates comparable quality to leading language models like GPT-4 across various tasks.
    - **Citations:**  OpenAI, 2023a; Cobbe et al., 2021; Hendrycks et al., 2021b; Zhou et al., 2023; Bai et al., 2023; Jiang et al., 2023; Cassano et al., 2023; Shi et al., 2022;  Hendrycks et al., 2021a; Wang et al., 2024b;  Touvron et al., 2023b;  An et al., 2023a;  Zhang et al., 2019;  Pang et al., 2022;  Jia and Liang, 2017;  Kiela et al., 2021;  Li et al., 2024c;  Wang et al., 2017;  Shaham et al., 2023;  Kamradt, 2023;  Zhang et al., 2024;  Srinivasan et al., 2023;  Li et al., 2023b;  Patil et al., 2023;  Yan et al., 2024
    - **Explanation:** The authors compare Llama 3's performance to GPT-4 and other leading models across a wide range of benchmarks, demonstrating its competitive capabilities.
- **Insight:** The authors emphasize the importance of data quality and diversity in achieving high model performance.
    - **Citations:**  Broder, 1997; Raffel et al., 2020; Joulin et al., 2017; Liu et al., 2019a; Touvron et al., 2023a; Sanh et al., 2019; Li et al., 2024b; OpenAI, 2023a; Cobbe et al., 2021; Hendrycks et al., 2021b; Blakeney et al., 2024;  Wenzek et al., 2019;  Abbas et al., 2023;  Xu et al., 2023;  Mahajan et al., 2018;  Mikolov et al., 2013;  Carlini et al., 2023;  Somepalli et al., 2023;  Farid, 2021;  Radford et al., 2021;  Yang et al., 2023a;  Lee et al., 2021;  Abbas et al., 2023;  Thiel, 2023;  DeepSeek-AI et al., 2024;  Chen et al., 2023;  Wei et al., 2024b;  Hardalov et al., 2020;  Wu et al., 2023;  Prokopidis et al., 2016;  Tiedemann, 2012;  Wei et al., 2022a;  Bizzoni et al., 2020;  Muennighoff et al., 2023;  Wang et al., 2022a;  Shi et al., 2022
    - **Explanation:** The authors demonstrate the importance of data quality and diversity through their detailed description of data curation and filtering techniques, highlighting the use of various methods like de-duplication, heuristic filtering, and model-based quality filtering.
- **Insight:** The authors highlight the importance of managing complexity in model development, opting for a standard dense Transformer architecture and a relatively simple post-training procedure.
    - **Citations:**  Vaswani et al., 2017; Ouyang et al., 2022; Schulman et al., 2017; Rafailov et al., 2023;  Shazeer et al., 2017;  Lewis et al., 2021;  Fedus et al., 2022;  Jiang et al., 2024;  Snowflake, 2024;  Mehta et al., 2024;  Team et al., 2024;  Abdin et al., 2024;  Chung et al., 2022;  Ouyang et al., 2022;  Kaufmann et al., 2023;  Bai et al., 2022;  Kwon et al., 2023;  Izmailov et al., 2019;  Wortsman et al., 2022;  Li et al., 2022
    - **Explanation:** The authors demonstrate their awareness of the trade-offs between model complexity and performance, opting for a simpler approach to model development and post-training.
- **Insight:** The authors emphasize the importance of safety in foundation models and describe their approach to ensuring safe and responsible use of Llama 3.
    - **Citations:**  Carlini et al., 2022;  Nasr et al., 2023;  Touvron et al., 2023b;  Samvelyan et al., 2024;  Ippolito et al., 2023;  Kassem et al., 2024;  Llama-Team, 2024;  Schick et al., 2024;  Singh et al., 2024;  Bhatt et al., 2023, 2024;  Vidgen et al., 2024;  Hartvigsen et al., 2022;  Röttger et al., 2023;  Anil et al., 2024;  Wallace et al., 2024;  Inan et al., 2023;  Chao et al., 2023;  Fathullah et al., 2024;  Le et al., 2024;  Costa-jussà et al., 2023;  Pratap et al., 2020;  Panayotov et al., 2015;  Wang et al., 2021a;  Conneau et al., 2023;  Google, 2023;  Lin et al., 2023;  Maaz et al., 2024;  Zhang et al., 2023;  Zhao et al., 2022;  Rubenstein et al., 2023;  Gekhman et al., 2024;  Mielke et al., 2020;  Touvron et al., 2023b;  Samvelyan et al., 2024;  Ippolito et al., 2023;  Kassem et al., 2024;  Llama-Team, 2024;  Schick et al., 2024;  Singh et al., 2024;  Bhatt et al., 2023, 2024;  Vidgen et al., 2024;  Hartvigsen et al., 2022;  Röttger et al., 2023;  Anil et al., 2024;  Wallace et al., 2024;  Inan et al., 2023;  Chao et al., 2023;  Fathullah et al., 2024;  Le et al., 2024;  Costa-jussà et al., 2023;  Pratap et al., 2020;  Panayotov et al., 2015;  Wang et al., 2021a;  Conneau et al., 2023;  Google, 2023;  Lin et al., 2023;  Maaz et al., 2024;  Zhang et al., 2023;  Zhao et al., 2022;  Rubenstein et al., 2023;  Gekhman et al., 2024;  Mielke et al., 2020;  Touvron et al., 2023b;  Samvelyan et al., 2024;  Ippolito et al., 2023;  Kassem et al., 2024;  Llama-Team, 2024;  Schick et al., 2024;  Singh et al., 2024;  Bhatt et al., 2023, 2024;  Vidgen et al., 2024;  Hartvigsen et al., 2022;  Röttger et al., 2023;  Anil et al., 2024;  Wallace et al., 2024;  Inan et al., 2023;  Chao et al., 2023;  Fathullah et al., 2024;  Le et al., 2024;  Costa-jussà et al., 2023;  Pratap et al., 2020;  Panayotov et al., 2015;  Wang et al., 2021a;  Conneau et al., 2023;  Google, 2023;  Lin et al., 2023;  Maaz et al., 2024;  Zhang et al., 2023;  Zhao et al., 2022;  Rubenstein et al., 2023;  Gekhman et al., 2024;  Mielke et al., 2020;  Touvron et al., 2023b;  Samvelyan et al., 2024;  Ippolito et al., 2023;  Kassem et al., 2024;  Llama-Team, 2024;  Schick et al., 2024;  Singh et al., 2024;  Bhatt et al., 2023, 2024;  Vidgen et al., 2024;  Hartvigsen et al., 2022;  Röttger et al., 2023;  Anil et al., 2024;  Wallace et al., 2024;  Inan et al., 2023;  Chao et al., 2023;  Fathullah et al., 2024;  Le et al., 2024;  Costa-jussà et al., 2023;  Pratap et al., 2020;  Panayotov et al., 2015;  Wang et al., 2021a;  Conneau et al., 2023;  Google, 2023;  Lin et al., 2023;  Maaz et al., 2024;  Zhang et al., 2023;  Zhao et al., 2022;  Rubenstein et al., 2023;  Gekhman et al., 2024;  Mielke et al., 2020;  Touvron et al., 2023b;  Samvelyan et al., 2024;  Ippolito et al., 2023;  Kassem et al., 2024;  Llama-Team, 2024;  Schick et al., 2024;  Singh et al., 2024;  Bhatt et al., 2023, 2024;  Vidgen et al., 2024;  Hartvigsen et al., 2022;  Röttger et al., 2023;  Anil et al., 2024;  Wallace et al., 2024;  Inan et al., 2023;  Chao et al., 2023;  Fathullah et al., 2024;  Le et al., 2024;  Costa-jussà et al., 2023;  Pratap et al., 2020;  Panayotov et al., 201